{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morris:\n",
    "    def __init__(self, df, variables):\n",
    "        self.df=df\n",
    "        self.variables=variables \n",
    "        \n",
    "    def multi_encode(self):\n",
    "        from sklearn import preprocessing\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = le.fit_transform(self.df[variable])\n",
    "            print(f\"label encoded {variable}\")\n",
    "            \n",
    "    def multi_drop(self):\n",
    "        for variable in self.variables:\n",
    "            self.df = self.df.drop(variable, axis=1)\n",
    "            print(f\"{variable} column is dropped\")\n",
    "        return self.df\n",
    "    \n",
    "    def multi_onehot(self):\n",
    "        import pandas as pd\n",
    "        for variable in self.variables:\n",
    "            self.df = pd.get_dummies(self.df, prefix = [variable], columns = [variable])\n",
    "            print(f\"{variable} column is one hot encoded\")\n",
    "        print(self.df.shape)\n",
    "        return self.df\n",
    "    \n",
    "    def normalisation(self):\n",
    "        import pandas as pd\n",
    "        temp=[]\n",
    "        from sklearn import preprocessing\n",
    "        temp.append(self.df.drop(self.variables, axis=1))\n",
    "        self.df = preprocessing.normalize(temp[0])\n",
    "        names = temp[0].columns\n",
    "        temp[0] = pd.DataFrame(self.df, columns=names)\n",
    "        print(f\"{self.variables} dropped, rest columns are normalised\")\n",
    "        return temp[0]\n",
    "            \n",
    "    def standardisation(self):\n",
    "        import pandas as pd\n",
    "        temp=[]\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        temp.append(self.df.drop(self.variables, axis=1))\n",
    "        self.df = scaler.fit_transform(temp[0])\n",
    "        names = temp[0].columns\n",
    "        temp[0] = pd.DataFrame(self.df, columns=names)\n",
    "        print(f\"{self.variables} dropped, rest columns are standardised\")\n",
    "        return temp[0]\n",
    "    \n",
    "    def change_str(self):\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = self.df[variable].astype(str)\n",
    "            print(f\"{variable} column changed to str\")\n",
    "        \n",
    "    def change_int(self):\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = self.df[variable].astype(int)\n",
    "            print(f\"{variable} column changed to int\")\n",
    "        \n",
    "    def change_float(self):\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = self.df[variable].astype(float)\n",
    "            print(f\"{variable} column changed to float\")\n",
    "\n",
    "    def movefront(self):\n",
    "        cols = self.df.columns.tolist()\n",
    "        remaining_cols = set(cols) - set(self.variables) \n",
    "        remaining_cols = list(remaining_cols)\n",
    "        new_cols = self.variables + remaining_cols\n",
    "        self.df = self.df[new_cols] \n",
    "        return self.df\n",
    "    \n",
    "    def moveend(self):\n",
    "        cols = self.df.columns.tolist()\n",
    "        remaining_cols = set(cols) - set(self.variables) \n",
    "        remaining_cols = list(remaining_cols)\n",
    "        new_cols = remaining_cols + self.variables\n",
    "        self.df = self.df[new_cols] \n",
    "        return self.df\n",
    "    \n",
    "    def group_by_mean(self):\n",
    "        temp = self.df.groupby(self.variables).size().reset_index(name='groupby_counts')\n",
    "        counts = temp['groupby_counts'].values.tolist()\n",
    "        self.df = self.df.groupby(variables).mean()\n",
    "        self.df['groupby_counts'] = counts\n",
    "        print(f\"Columns are groped, rest columns summarised by mean, how many columns summarised by mean are counted\")\n",
    "        return self.df\n",
    "    \n",
    "class Morris_data:\n",
    "    def __init__(self, df):\n",
    "        self.df=df\n",
    "        \n",
    "    def trim(self):\n",
    "        self.df.columns = self.df.columns.str.strip()\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        self.df.columns = self.df.columns.str.lower()\n",
    "        self.df.columns = self.df.columns.str.replace(' ','_')\n",
    "        df_obj = self.df.select_dtypes(['object'])\n",
    "        self.df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "        print(\"All column names have been striped, lowered case, replaced space with underscore if any\")\n",
    "        print(\"Dropped duplicated instances if any\")\n",
    "        print(\"Categorical instances have been striped\")\n",
    "        return self.df\n",
    "    \n",
    "    def impute(self):\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == object:\n",
    "                imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "                self.df[col] = imp.fit_transform(self.df[[col]]).ravel()\n",
    "                print(f\"imputed mode for {col}\")\n",
    "            else:\n",
    "                impmean = SimpleImputer(strategy=\"mean\")\n",
    "                self.df[col] = impmean.fit_transform(self.df[[col]]).ravel()\n",
    "                print(f\"imputed mean for {col}\")\n",
    "                \n",
    "    def iqr(self):\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype != object:\n",
    "                Q1 = self.df[col].quantile(0.25)\n",
    "                Q3 = self.df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                S = 1.5*IQR\n",
    "                LB = Q1 - S\n",
    "                UB = Q3 + S\n",
    "                self.df.loc[self.df[col] > UB,col] = UB\n",
    "                self.df.loc[self.df[col] < LB,col] = LB\n",
    "                print(f\"{col} outliers are replaced by [{LB}, {UB}] by IQR\")\n",
    "            else:\n",
    "                break\n",
    "        print(\"FINISHED - All column outliers are replaced by lower or upper boundary of interquartile rules\")\n",
    "        return self.df\n",
    "    \n",
    "    def select_numeric(self):\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        newdf = self.df.select_dtypes(include=numerics)\n",
    "        return newdf\n",
    "    \n",
    "    def powertransform(self):\n",
    "        from sklearn.preprocessing import PowerTransformer\n",
    "        names = self.df.columns\n",
    "        df_filter = self.df[self.df > 0]\n",
    "        pt = PowerTransformer(method='box-cox')\n",
    "        temp_transform = pt.fit_transform(df_filter)\n",
    "        df_new = pd.DataFrame(temp_transform, columns=names)\n",
    "        return df_new\n",
    "    \n",
    "    def distribution(self):\n",
    "        list(set(self.df.dtypes.tolist()))\n",
    "        # include only float and integer\n",
    "        df_num = self.df.select_dtypes(include = ['float64', 'int64'])\n",
    "        return df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);\n",
    "    \n",
    "    def corr_sort_positive(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        corr_matrix = self.df.corr()\n",
    "        sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "                          .stack()\n",
    "                          .sort_values(ascending=False))\n",
    "        corr = pd.DataFrame(sol, columns=['corr'])\n",
    "        return corr.head(50)\n",
    "    \n",
    "    def corr_sort_negative(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        corr_matrix = self.df.corr()\n",
    "        sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "                          .stack()\n",
    "                          .sort_values(ascending=True))\n",
    "        corr = pd.DataFrame(sol, columns=['corr'])\n",
    "        return corr.head(50)\n",
    "    \n",
    "class Morris_discrete:\n",
    "    def __init__(self, df, variables, categories):\n",
    "        self.df=df\n",
    "        self.variables=variables \n",
    "        self.categories=categories \n",
    "        \n",
    "    def qcut(self):\n",
    "        import pandas as pd\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = pd.qcut(self.df[variable], q = self.categories, precision = 0)\n",
    "            return self.df\n",
    "        \n",
    "    def bincut(self):\n",
    "        import pandas as pd\n",
    "        for variable in self.variables:\n",
    "            self.df[variable] = pd.cut(self.df[variable], bins = self.categories)\n",
    "            \n",
    "class Morris_toy:\n",
    "    def __init__(self, df):\n",
    "        self.df=df\n",
    "        \n",
    "    def boston(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from sklearn.datasets import load_boston\n",
    "        boston = load_boston()\n",
    "        self.df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "        self.df['target'] = pd.DataFrame(boston.target, columns = np.array(['target']))\n",
    "        return self.df\n",
    "    \n",
    "    def iris(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from sklearn.datasets import load_iris\n",
    "        iris = load_iris()\n",
    "        self.df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "        self.df['target'] = pd.DataFrame(iris.target, columns = np.array(['target']))\n",
    "        return self.df\n",
    "    \n",
    "    def digits(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from sklearn.datasets import load_digits\n",
    "        digits = load_digits()\n",
    "        self.df = pd.DataFrame(digits.data, columns = digits.feature_names)\n",
    "        self.df['target'] = pd.DataFrame(digits.target, columns = np.array(['target']))\n",
    "        return self.df\n",
    "    \n",
    "    def diabetes(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from sklearn.datasets import load_diabetes\n",
    "        diabetes = load_diabetes()\n",
    "        self.df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "        self.df['target'] = pd.DataFrame(diabetes.target, columns = np.array(['target']))\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lee Kah Win\\\\Desktop'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Set path for new working directory\n",
    "path = \"C:/Users/Lee Kah Win/Desktop/\"\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('covid_records.csv')\n",
    "df0 = df\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = Morris_data(df0).trim()\n",
    "encode = ['locations_visited', 'health_condition']\n",
    "Morris(df0, encode).multi_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['mysejahtera_id', 'user_id', 'name', 'email']\n",
    "df0 = Morris(df0, drop).multi_drop()\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classification ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morris_classification:\n",
    "    def __init__(self, score):\n",
    "        self.score=score\n",
    "    \n",
    "    def rfc(self):\n",
    "        print(\"Random Forest Classification is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        rfc=RandomForestClassifier(random_state=0)\n",
    "        param_grid_rfr = { \n",
    "            'n_estimators': [200, 500],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : [4,5,6,7,8,10, None],\n",
    "            'criterion' :['gini', 'entropy']\n",
    "        }\n",
    "        record_score = []\n",
    "        record_param = []\n",
    "        performance_df['rfr_training'] = record_score\n",
    "        performance_df['rfr_param'] = record_param\n",
    "        for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "            grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid_rfr, cv= 5, scoring = self.score)\n",
    "            grid_result = grid_search.fit(X_train, y_train.values.ravel())\n",
    "            record_score.append(grid_result.best_score_)\n",
    "            record_param.append(grid_search.best_params_)\n",
    "            print(grid_search.best_params_)\n",
    "            print(f\"Best {self.score} : {grid_result.best_score_}\")\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df\n",
    "\n",
    "    def naive_bayes(self):\n",
    "        print(\"Naive Bayes Classification is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        from sklearn.naive_bayes import BernoulliNB\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        naive_bayes = {'Gaussian_Naive_Bayes': GaussianNB(), \n",
    "                       'Bernoulli_Naive_Bayes': BernoulliNB(binarize = 0.0), \n",
    "                       'Multinomial_Naive_Bayes': MultinomialNB()}\n",
    "        for key, value in naive_bayes.items():\n",
    "            record_score = []\n",
    "            performance_df[key] = record_score\n",
    "            for (key_X_train,X_train), (key_y_train,y_train) , (key_X_test,X_test), (key_y_test,y_test) in zip(X_train_data.items(), y_train_data.items(), X_test_data.items(), y_test_data.items()):\n",
    "                x = cross_val_score(value, X_train, y_train.values.ravel(), cv=5,scoring = self.score)\n",
    "                record_score.append(x.mean())\n",
    "                print(f\"{key} {key_X_train} {self.score} : {x.mean()}\")\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df\n",
    "    \n",
    "    def knn(self):\n",
    "        print(\"K-Nearest Neighbors Classification is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import r2_score, median_absolute_error, mean_squared_error\n",
    "        knn = KNeighborsClassifier()\n",
    "        start, end = 2, 40\n",
    "        k_range = []  \n",
    "        # iterating each number in list\n",
    "        for num in range(start, end + 1):\n",
    "            if num % 2 != 0:\n",
    "                k_range.append(num)\n",
    "        weight_options = [\"uniform\", \"distance\"]\n",
    "        param_grid_values = dict(n_neighbors = k_range, weights = weight_options) \n",
    "        record_score = []\n",
    "        record_param = []\n",
    "        performance_df['knn_training'] = record_score\n",
    "        performance_df['knn_param'] = record_param\n",
    "        for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "            grid_search = GridSearchCV(estimator=knn, param_grid=param_grid_values, cv= 5, scoring = self.score)\n",
    "            grid_result = grid_search.fit(X_train, y_train.values.ravel())\n",
    "            record_score.append(grid_result.best_score_)\n",
    "            record_param.append(grid_search.best_params_)\n",
    "            print(grid_search.best_params_)\n",
    "            print(f\"Best {self.score} : {grid_result.best_score_}\")\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df\n",
    "    \n",
    "    def dtc(self):\n",
    "        print(\"Decision Tree Classification is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        dtc = DecisionTreeClassifier(random_state=0)\n",
    "        sample_split_range = list(range(2, 10))\n",
    "        criterion_options = ['gini', 'entropy']\n",
    "        max_depth_options = [None, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41]\n",
    "        num_leafs = [1, 5, 10, 20, 50]\n",
    "        record_score = []\n",
    "        record_param = []\n",
    "        performance_df['dtc_training'] = record_score\n",
    "        performance_df['dtc_param'] = record_param \n",
    "        param_grid_values = dict(min_samples_split=sample_split_range, \n",
    "                          criterion = criterion_options, max_depth = max_depth_options,\n",
    "                         min_samples_leaf = num_leafs)\n",
    "        for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "            grid_search = GridSearchCV(estimator=dtc, param_grid=param_grid_values, cv= 5, scoring = self.score)\n",
    "            grid_result = grid_search.fit(X_train, y_train)\n",
    "            record_score.append(grid_result.best_score_)\n",
    "            record_param.append(grid_search.best_params_)\n",
    "            print(grid_search.best_params_)\n",
    "            print(f\"Best {self.score} : {grid_result.best_score_}\")\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df\n",
    "    \n",
    "    def svc(self):\n",
    "        print(\"Support Vector Classification is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        SVC = {'SVC_LINEAR': SVC(kernel='linear'), \n",
    "               'SVC_POLY': SVC(kernel='poly'), 'SVC_RBF': SVC(kernel='rbf'), \n",
    "               'SVC_SIGMOID': SVC(kernel='sigmoid')}\n",
    "        SVC_param = {'SVC_LINEAR_param': 1,'SVC_POLY_param': 2, 'SVC_RBF_param': 3, 'SVC_SIGMOID_param': 4}\n",
    "        for (key, value), (param_key, param_value) in zip(SVC.items(), SVC_param.items()):\n",
    "            record_score = []\n",
    "            record_param = []\n",
    "            performance_df[key] = record_score\n",
    "            performance_df[param_key] = record_param \n",
    "            for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "                if key == 'LINEAR':\n",
    "                    param_grid = {'C': [0.01,0.0125,0.02,0.03,0.04,0.05 ]}\n",
    "                elif key == 'POLY':\n",
    "                    param_grid = {'C': [0.01,0.1,1, 10, 25, 50,100, 1000,10000], 'degree': [2, 3, 4, 5], 'gamma': ['scale','auto']}\n",
    "                elif key == 'RBF':\n",
    "                    param_grid = {'C': [0.5,0.75,1, 1.25,1.5,1.75,2],'gamma': ['scale','auto'],'kernel': ['rbf']}\n",
    "                else:\n",
    "                    param_grid = {'C': [0.1,0.125,0.2,0.3,0.4 ], 'gamma': ['scale','auto']}\n",
    "                grid_search = GridSearchCV(value, param_grid, cv=5, scoring=self.score, n_jobs=-1)\n",
    "                grid_result = grid_search.fit(X_train, y_train.values.ravel())\n",
    "                record_score.append(grid_result.best_score_)\n",
    "                record_param.append(grid_search.best_params_)\n",
    "                print(f\"{key} - {grid_search.best_params_}\")\n",
    "                print(f\"Best {self.score} {key_X_train}: {grid_result.best_score_}\")\n",
    "                print('') \n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df\n",
    "    \n",
    "    def voting(self):\n",
    "        print(\"Ensemble Learning Voting Classifier is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.ensemble import VotingClassifier\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        model_voting = VotingClassifier(estimators = [('clf1', clf1), ('clf2',clf2),\n",
    "                                                     ('clf3', clf3), ('clf4', clf4),\n",
    "                                                     ('clf5', clf5)])\n",
    "        record_score = []\n",
    "        performance_df['voting_training'] = record_score\n",
    "        for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "            scores = cross_val_score(model_voting, X_train, y_train.values.ravel(), cv = 5, scoring = self.score)\n",
    "            print(f\"{key_X_train} {self.score} = {scores.mean()}\")\n",
    "            record_score.append(scores.mean())\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df, model_voting\n",
    "    \n",
    "    def stacking(self):\n",
    "        print(\"Ensemble Learning Stacking Classifier is executed\")\n",
    "        print(\"Found the best parameters and best score with GridSearchCV\")\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        from sklearn.ensemble import StackingClassifier\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        model_stacking = StackingClassifier(estimators = [ ('clf1',clf1), ('clf2',clf2),\n",
    "                                                          ('clf3', clf3), ('clf4', clf4),\n",
    "                                                          ('clf5', clf5)],\n",
    "                                            final_estimator = clf5)\n",
    "        record_score = []\n",
    "        performance_df['stacking_training'] = record_score\n",
    "        for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "            scores = cross_val_score(model_stacking, X_train, y_train.values.ravel(), cv = 5, scoring = self.score)\n",
    "            print(f\"{key_X_train} {self.score} = {scores.mean()}\")\n",
    "            record_score.append(scores.mean())\n",
    "        print(\"Executed time is %s seconds \" % (time.time() - start_time))\n",
    "        print(\"Values are stored into a dataframe\")\n",
    "        return performance_df, model_stacking\n",
    "    \n",
    "    def predict(self):\n",
    "        from sklearn import metrics \n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "        for key, model in models.items():\n",
    "            record_score = []\n",
    "            performance_df[key] = record_score\n",
    "            for (key_X_train,X_train), (key_y_train,y_train) , (key_X_test,X_test), (key_y_test,y_test) in zip(X_train_data.items(), y_train_data.items(), X_test_data.items(), y_test_data.items()):\n",
    "                model.fit(X_train, y_train.values.ravel())\n",
    "                test_predict = model.predict(X_test)\n",
    "                record_score.append(metrics.accuracy_score(y_test.values.ravel(), test_predict))\n",
    "                print(f\"{key_X_train} {key} {self.score}: {metrics.accuracy_score(y_test.values.ravel(), test_predict)}\")\n",
    "        return performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To identify the next individual that will contribute clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df0[['new_cluster_contributor']]\n",
    "drop = ['new_cluster_contributor']\n",
    "df0 = Morris(df0, drop).multi_drop()\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set and Testing Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morris_split:\n",
    "    def __init__(self, X, y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    \n",
    "    def train_test_split(self):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.2, random_state=0)\n",
    "        print(f\"the training shape of x and y are {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"the testing shape of x and y are {X_test.shape}, {y_test.shape}\")\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Morris_split(df0, y).train_test_split()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = {}\n",
    "performance_df['datasets'] = ['df0']\n",
    "X_train_data = {'df0': X_train}\n",
    "y_train_data = {'df0': y_train}\n",
    "X_test_data = {'df0': X_test}\n",
    "y_test_data = {'df0': y_test}\n",
    "# test workability\n",
    "for (key_X_train,X_train), (key_y_train,y_train) in zip(X_train_data.items(), y_train_data.items()):\n",
    "    print(key_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the data with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Morris_classification('accuracy').naive_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the data with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Morris_classification('accuracy').dtc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the data with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Morris_classification('accuracy').rfc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data=performance_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf1 = DecisionTreeClassifier(random_state=0, criterion= 'gini', \n",
    "                      max_depth= 7, min_samples_leaf= 5, min_samples_split= 2)\n",
    "clf2 = RandomForestClassifier(criterion= 'entropy', max_depth= 10, \n",
    "        max_features= 'log2', n_estimators= 500)\n",
    "clf3 = KNeighborsClassifier(n_neighbors= 35, weights= 'distance')\n",
    "clf4 = SVC(kernel='linear', C= 0.03, gamma= 'scale')\n",
    "clf5 = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Naive Bayes into Testing Set to see the generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "clf5.fit(X_train, y_train.values.ravel())\n",
    "test_predict = clf5.predict(X_test)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : \", metrics.accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the data of the red flagged user predicted by Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted_new_contributors'] = test_predict.tolist()\n",
    "X_test_positive = X_test[X_test['predicted_new_contributors']==1]\n",
    "X_test_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = []\n",
    "for row in X_test_positive.index:\n",
    "    row_list.append(row)\n",
    "row_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the red flagged individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_new_cluster_contributor = df.iloc[row_list]\n",
    "predicted_new_cluster_contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = [['NAME', 'MYSEJAHTERA ID', 'ACTION', 'NOTIFICATIONS']]\n",
    "for index, row in predicted_new_cluster_contributor.iterrows():\n",
    "    temp = []\n",
    "    temp.append(row['NAME'])\n",
    "    temp.append(row['MYSEJAHTERA ID'])\n",
    "    temp.append(\"Need to be Quarantined Immediately\")\n",
    "    temp.append(\"Notification Sent, MySej Updated\")\n",
    "    big.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in predicted_new_cluster_contributor.iterrows():\n",
    "    print(f\"{row['NAME']} cannot go anywhere, any scanning in Mysejahtera LAW ENFORCEMENT will be noticed for 14 days\")\n",
    "    print(f\"A **STAY_AT_HOME_ORDER** was email has been sent to {row['NAME']} at {row['EMAIL']}\")\n",
    "    print(f\"**RED FLAGGED** has been updated to {row['NAME']} in My sejahtera ID: {row['MYSEJAHTERA ID']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violations Automating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_number = 0\n",
    "Farah = {'violations': scan_number }\n",
    "Farah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envisioning the violation scan by the mysejahtera app during quarantine period\n",
    "scan_number = scan_number+1\n",
    "scan_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_grop = 'B40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violations_monitor(scan_number):\n",
    "    if scan_number > 0:\n",
    "        if scan_number ==1:\n",
    "            if income_grop == 'B40':\n",
    "                print('2 more violations - RM800 punishment will be imposed.')\n",
    "            elif income_grop == 'M40':\n",
    "                print('2 more violations - RM2500 punishment will be imposed.')\n",
    "            elif income_grop == 'T40':\n",
    "                print('2 more violations - RM5000 punishment will be imposed.')\n",
    "        elif scan_number ==2:\n",
    "            if income_grop == 'B40':\n",
    "                print('1 more violation - RM800 punishment will be imposed.')\n",
    "            elif income_grop == 'M40':\n",
    "                print('1 more violation - RM2500 punishment will be imposed.')\n",
    "            elif income_grop == 'T40':\n",
    "                print('1 more violation - RM5000 punishment will be imposed.')       \n",
    "        elif scan_number ==3:\n",
    "            if income_grop == 'B40':\n",
    "                print('RM800 punishment was imposed. Link created to make a transfer in 14 days')\n",
    "            elif income_grop == 'M40':\n",
    "                print('RM2500 punishment was imposed. Link created to make a transfer in 14 days')\n",
    "            elif income_grop == 'T40':\n",
    "                print('RM5000 punishment was imposed. Link created to make a transfer in 14 days')\n",
    "    else:\n",
    "        print('no violations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_monitor(scan_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Unsupervised Learning Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we accurately predict know which business location to close down to mitigate the COVID-19?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYSEJAHTERA ID</th>\n",
       "      <th>USER ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LOCATIONS VISITED LEAD TO COVID19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>5/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>MAMAK213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>6/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>7/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>8/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>SHOP_XX5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>9/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>10/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>MAMAK213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M2</td>\n",
       "      <td>2</td>\n",
       "      <td>ALI</td>\n",
       "      <td>11/5/2021</td>\n",
       "      <td>ALI@gmail.com</td>\n",
       "      <td>62</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>5/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>6/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>7/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>SHOP_XX5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>8/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>SHOP_XX6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>9/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>MAMAK213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M3</td>\n",
       "      <td>3</td>\n",
       "      <td>FARAH</td>\n",
       "      <td>10/5/2021</td>\n",
       "      <td>FARAH@gmail.com</td>\n",
       "      <td>23</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>11/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>12/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>13/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>14/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>15/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M4</td>\n",
       "      <td>4</td>\n",
       "      <td>LEE</td>\n",
       "      <td>16/5/2021</td>\n",
       "      <td>LEE@gmail.com</td>\n",
       "      <td>30</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MYSEJAHTERA ID  USER ID   NAME       DATE            EMAIL  AGE  \\\n",
       "0              M2        2    ALI   5/5/2021    ALI@gmail.com   62   \n",
       "1              M2        2    ALI   6/5/2021    ALI@gmail.com   62   \n",
       "2              M2        2    ALI   7/5/2021    ALI@gmail.com   62   \n",
       "3              M2        2    ALI   8/5/2021    ALI@gmail.com   62   \n",
       "4              M2        2    ALI   9/5/2021    ALI@gmail.com   62   \n",
       "5              M2        2    ALI  10/5/2021    ALI@gmail.com   62   \n",
       "6              M2        2    ALI  11/5/2021    ALI@gmail.com   62   \n",
       "7              M3        3  FARAH   5/5/2021  FARAH@gmail.com   23   \n",
       "8              M3        3  FARAH   6/5/2021  FARAH@gmail.com   23   \n",
       "9              M3        3  FARAH   7/5/2021  FARAH@gmail.com   23   \n",
       "10             M3        3  FARAH   8/5/2021  FARAH@gmail.com   23   \n",
       "11             M3        3  FARAH   9/5/2021  FARAH@gmail.com   23   \n",
       "12             M3        3  FARAH  10/5/2021  FARAH@gmail.com   23   \n",
       "13             M4        4    LEE  11/5/2021    LEE@gmail.com   30   \n",
       "14             M4        4    LEE  12/5/2021    LEE@gmail.com   30   \n",
       "15             M4        4    LEE  13/5/2021    LEE@gmail.com   30   \n",
       "16             M4        4    LEE  14/5/2021    LEE@gmail.com   30   \n",
       "17             M4        4    LEE  15/5/2021    LEE@gmail.com   30   \n",
       "18             M4        4    LEE  16/5/2021    LEE@gmail.com   30   \n",
       "\n",
       "   LOCATIONS VISITED LEAD TO COVID19  \n",
       "0                           MAMAK213  \n",
       "1                           SHOP_XX3  \n",
       "2                           SHOP_XX4  \n",
       "3                           SHOP_XX5  \n",
       "4                           SHOP_XX3  \n",
       "5                           MAMAK213  \n",
       "6                   COVID19_DETECTED  \n",
       "7                           SHOP_XX3  \n",
       "8                           SHOP_XX4  \n",
       "9                           SHOP_XX5  \n",
       "10                          SHOP_XX6  \n",
       "11                          MAMAK213  \n",
       "12                  COVID19_DETECTED  \n",
       "13                          SHOP_XX3  \n",
       "14                          SHOP_XX4  \n",
       "15                          SHOP_XX3  \n",
       "16                          SHOP_XX3  \n",
       "17                          SHOP_XX4  \n",
       "18                  COVID19_DETECTED  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('location_records.csv')\n",
    "df2 = df1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MYSEJAHTERA ID', 'USER ID', 'NAME', 'DATE', 'EMAIL', 'AGE',\n",
       "       'LOCATIONS VISITED LEAD TO COVID19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER ID column is dropped\n",
      "NAME column is dropped\n",
      "DATE column is dropped\n",
      "EMAIL column is dropped\n",
      "AGE column is dropped\n",
      "All column names have been striped, lowered case, replaced space with underscore if any\n",
      "Dropped duplicated instances if any\n",
      "Categorical instances have been striped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee Kah Win\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mysejahtera_id</th>\n",
       "      <th>locations_visited_lead_to_covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2</td>\n",
       "      <td>MAMAK213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M2</td>\n",
       "      <td>SHOP_XX5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M2</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M3</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M3</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M3</td>\n",
       "      <td>SHOP_XX5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M3</td>\n",
       "      <td>SHOP_XX6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M3</td>\n",
       "      <td>MAMAK213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M3</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M4</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M4</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mysejahtera_id locations_visited_lead_to_covid19\n",
       "0              M2                          MAMAK213\n",
       "1              M2                          SHOP_XX3\n",
       "2              M2                          SHOP_XX4\n",
       "3              M2                          SHOP_XX5\n",
       "6              M2                  COVID19_DETECTED\n",
       "7              M3                          SHOP_XX3\n",
       "8              M3                          SHOP_XX4\n",
       "9              M3                          SHOP_XX5\n",
       "10             M3                          SHOP_XX6\n",
       "11             M3                          MAMAK213\n",
       "12             M3                  COVID19_DETECTED\n",
       "13             M4                          SHOP_XX3\n",
       "14             M4                          SHOP_XX4\n",
       "18             M4                  COVID19_DETECTED"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = ['USER ID', 'NAME', 'DATE', 'EMAIL', 'AGE']\n",
    "df2 = Morris(df2, drop).multi_drop()\n",
    "df2 = Morris_data(df2).trim()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mysejahtera_id</th>\n",
       "      <th>locations_visited_lead_to_covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2</td>\n",
       "      <td>[MAMAK213, SHOP_XX3, SHOP_XX4, SHOP_XX5, COVID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M3</td>\n",
       "      <td>[SHOP_XX3, SHOP_XX4, SHOP_XX5, SHOP_XX6, MAMAK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4</td>\n",
       "      <td>[SHOP_XX3, SHOP_XX4, COVID19_DETECTED]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mysejahtera_id                  locations_visited_lead_to_covid19\n",
       "0             M2  [MAMAK213, SHOP_XX3, SHOP_XX4, SHOP_XX5, COVID...\n",
       "1             M3  [SHOP_XX3, SHOP_XX4, SHOP_XX5, SHOP_XX6, MAMAK...\n",
       "2             M4             [SHOP_XX3, SHOP_XX4, COVID19_DETECTED]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group all movieId by userId for association rules mining\n",
    "df_all = df2.groupby(\"mysejahtera_id\")[\"locations_visited_lead_to_covid19\"].apply(list).reset_index()\n",
    "print(df_all.shape)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all data shape : (3, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COVID19_DETECTED</th>\n",
       "      <th>MAMAK213</th>\n",
       "      <th>SHOP_XX3</th>\n",
       "      <th>SHOP_XX4</th>\n",
       "      <th>SHOP_XX5</th>\n",
       "      <th>SHOP_XX6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COVID19_DETECTED  MAMAK213  SHOP_XX3  SHOP_XX4  SHOP_XX5  SHOP_XX6\n",
       "0                 1         1         1         1         1         0\n",
       "1                 1         1         1         1         1         1\n",
       "2                 1         0         1         1         0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "df_all.locations_visited_lead_to_covid19 = df_all.locations_visited_lead_to_covid19\n",
    "s = df_all['locations_visited_lead_to_covid19'].explode()\n",
    "df_all = df_all[['mysejahtera_id']].join(pd.crosstab(s.index, s))\n",
    "df_all = df_all.drop('mysejahtera_id', axis = 1)\n",
    "print(f\"df_all data shape : {df_all.shape}\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association(data_rating):\n",
    "    frequent = apriori(data_rating, min_support = 1, use_colnames = True)\n",
    "    frequent['length'] = frequent['itemsets'].apply(lambda x: len(x))\n",
    "    frequent[(frequent['length'] == 1) & \\\n",
    "             (frequent['support'] >= 1)]\n",
    "    data_rating = association_rules(frequent, metric = \"lift\", min_threshold = 1)\n",
    "    data_rating = data_rating[(data_rating['lift'] >= 1) & (data_rating['confidence'] >= 1)]\n",
    "    return data_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_data = association(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(SHOP_XX3, SHOP_XX4)</td>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(SHOP_XX3, COVID19_DETECTED)</td>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(SHOP_XX4, COVID19_DETECTED)</td>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(SHOP_XX3)</td>\n",
       "      <td>(SHOP_XX4, COVID19_DETECTED)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(SHOP_XX4)</td>\n",
       "      <td>(SHOP_XX3, COVID19_DETECTED)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(COVID19_DETECTED)</td>\n",
       "      <td>(SHOP_XX3, SHOP_XX4)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     antecedents                   consequents  \\\n",
       "0                     (SHOP_XX3)            (COVID19_DETECTED)   \n",
       "1             (COVID19_DETECTED)                    (SHOP_XX3)   \n",
       "2                     (SHOP_XX4)            (COVID19_DETECTED)   \n",
       "3             (COVID19_DETECTED)                    (SHOP_XX4)   \n",
       "4                     (SHOP_XX3)                    (SHOP_XX4)   \n",
       "5                     (SHOP_XX4)                    (SHOP_XX3)   \n",
       "6           (SHOP_XX3, SHOP_XX4)            (COVID19_DETECTED)   \n",
       "7   (SHOP_XX3, COVID19_DETECTED)                    (SHOP_XX4)   \n",
       "8   (SHOP_XX4, COVID19_DETECTED)                    (SHOP_XX3)   \n",
       "9                     (SHOP_XX3)  (SHOP_XX4, COVID19_DETECTED)   \n",
       "10                    (SHOP_XX4)  (SHOP_XX3, COVID19_DETECTED)   \n",
       "11            (COVID19_DETECTED)          (SHOP_XX3, SHOP_XX4)   \n",
       "\n",
       "    antecedent support  consequent support  support  confidence  lift  \\\n",
       "0                  1.0                 1.0      1.0         1.0   1.0   \n",
       "1                  1.0                 1.0      1.0         1.0   1.0   \n",
       "2                  1.0                 1.0      1.0         1.0   1.0   \n",
       "3                  1.0                 1.0      1.0         1.0   1.0   \n",
       "4                  1.0                 1.0      1.0         1.0   1.0   \n",
       "5                  1.0                 1.0      1.0         1.0   1.0   \n",
       "6                  1.0                 1.0      1.0         1.0   1.0   \n",
       "7                  1.0                 1.0      1.0         1.0   1.0   \n",
       "8                  1.0                 1.0      1.0         1.0   1.0   \n",
       "9                  1.0                 1.0      1.0         1.0   1.0   \n",
       "10                 1.0                 1.0      1.0         1.0   1.0   \n",
       "11                 1.0                 1.0      1.0         1.0   1.0   \n",
       "\n",
       "    leverage  conviction  \n",
       "0        0.0         inf  \n",
       "1        0.0         inf  \n",
       "2        0.0         inf  \n",
       "3        0.0         inf  \n",
       "4        0.0         inf  \n",
       "5        0.0         inf  \n",
       "6        0.0         inf  \n",
       "7        0.0         inf  \n",
       "8        0.0         inf  \n",
       "9        0.0         inf  \n",
       "10       0.0         inf  \n",
       "11       0.0         inf  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2a_2c(rules_data):\n",
    "    import numpy as np\n",
    "    a = [list(x) for x in rules_data.antecedents.values]\n",
    "    c = [list(x) for x in rules_data.consequents.values]\n",
    "    r = pd.DataFrame(np.array(a),\n",
    "                       columns=['antecedents'])\n",
    "    c = pd.DataFrame(np.array(c),\n",
    "                       columns=['consequents'])\n",
    "    r['consequents'] = c\n",
    "    r[['antecedent 1','antecedent 2']] = pd.DataFrame(r.antecedents.tolist(), index= r.index)\n",
    "    r[['consequent 1', 'consequent 2']] = pd.DataFrame(r.consequents.tolist(), index= r.index)\n",
    "    r.drop(['antecedents','consequents'],inplace=True,axis=1)\n",
    "    lift = rules_data[['lift']].reset_index(drop = True)\n",
    "    r['lift'] = lift\n",
    "    confidence = rules_data[['confidence']].reset_index(drop = True)\n",
    "    r['confidence'] = confidence\n",
    "    support = rules_data[['support']].reset_index(drop = True)\n",
    "    r['support'] = support\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedent 1</th>\n",
       "      <th>antecedent 2</th>\n",
       "      <th>consequent 1</th>\n",
       "      <th>consequent 2</th>\n",
       "      <th>lift</th>\n",
       "      <th>confidence</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        antecedent 1      antecedent 2      consequent 1      consequent 2  \\\n",
       "0           SHOP_XX3              None  COVID19_DETECTED              None   \n",
       "1   COVID19_DETECTED              None          SHOP_XX3              None   \n",
       "2           SHOP_XX4              None  COVID19_DETECTED              None   \n",
       "3   COVID19_DETECTED              None          SHOP_XX4              None   \n",
       "4           SHOP_XX3              None          SHOP_XX4              None   \n",
       "5           SHOP_XX4              None          SHOP_XX3              None   \n",
       "6           SHOP_XX3          SHOP_XX4  COVID19_DETECTED              None   \n",
       "7           SHOP_XX3  COVID19_DETECTED          SHOP_XX4              None   \n",
       "8           SHOP_XX4  COVID19_DETECTED          SHOP_XX3              None   \n",
       "9           SHOP_XX3              None          SHOP_XX4  COVID19_DETECTED   \n",
       "10          SHOP_XX4              None          SHOP_XX3  COVID19_DETECTED   \n",
       "11  COVID19_DETECTED              None          SHOP_XX3          SHOP_XX4   \n",
       "\n",
       "    lift  confidence  support  \n",
       "0    1.0         1.0      1.0  \n",
       "1    1.0         1.0      1.0  \n",
       "2    1.0         1.0      1.0  \n",
       "3    1.0         1.0      1.0  \n",
       "4    1.0         1.0      1.0  \n",
       "5    1.0         1.0      1.0  \n",
       "6    1.0         1.0      1.0  \n",
       "7    1.0         1.0      1.0  \n",
       "8    1.0         1.0      1.0  \n",
       "9    1.0         1.0      1.0  \n",
       "10   1.0         1.0      1.0  \n",
       "11   1.0         1.0      1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asso_results = transform2a_2c(rules_data)\n",
    "asso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedent 1</th>\n",
       "      <th>antecedent 2</th>\n",
       "      <th>consequent 1</th>\n",
       "      <th>consequent 2</th>\n",
       "      <th>lift</th>\n",
       "      <th>confidence</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SHOP_XX4</td>\n",
       "      <td>None</td>\n",
       "      <td>SHOP_XX3</td>\n",
       "      <td>COVID19_DETECTED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedent 1 antecedent 2      consequent 1      consequent 2  lift  \\\n",
       "0      SHOP_XX3         None  COVID19_DETECTED              None   1.0   \n",
       "2      SHOP_XX4         None  COVID19_DETECTED              None   1.0   \n",
       "6      SHOP_XX3     SHOP_XX4  COVID19_DETECTED              None   1.0   \n",
       "9      SHOP_XX3         None          SHOP_XX4  COVID19_DETECTED   1.0   \n",
       "10     SHOP_XX4         None          SHOP_XX3  COVID19_DETECTED   1.0   \n",
       "\n",
       "    confidence  support  \n",
       "0          1.0      1.0  \n",
       "2          1.0      1.0  \n",
       "6          1.0      1.0  \n",
       "9          1.0      1.0  \n",
       "10         1.0      1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asso_results_filter = asso_results[(asso_results['consequent 2']=='COVID19_DETECTED') | \n",
    "                                   (asso_results['consequent 1']=='COVID19_DETECTED')]\n",
    "asso_results_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedent 1 antecedent 2      consequent 1      consequent 2  lift  \\\n",
      "0      SHOP_XX3         None  COVID19_DETECTED              None   1.0   \n",
      "2      SHOP_XX4         None  COVID19_DETECTED              None   1.0   \n",
      "6      SHOP_XX3     SHOP_XX4  COVID19_DETECTED              None   1.0   \n",
      "9      SHOP_XX3         None          SHOP_XX4  COVID19_DETECTED   1.0   \n",
      "10     SHOP_XX4         None          SHOP_XX3  COVID19_DETECTED   1.0   \n",
      "\n",
      "    confidence  support  \n",
      "0          1.0      1.0  \n",
      "2          1.0      1.0  \n",
      "6          1.0      1.0  \n",
      "9          1.0      1.0  \n",
      "10         1.0      1.0  \n"
     ]
    }
   ],
   "source": [
    "print(asso_results_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SHOP_XX3', 'SHOP_XX4', 'SHOP_XX3', 'SHOP_XX3', 'SHOP_XX4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = asso_results_filter[['antecedent 1']]\n",
    "filtered = filtered.values.tolist()\n",
    "flat_list = [item for sublist in filtered for item in sublist]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "    list_set = set(list1)\n",
    "    unique_list = (list(list_set))\n",
    "    temp = []\n",
    "    for x in unique_list:\n",
    "        temp.append(x)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SHOP_XX3', 'SHOP_XX4']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = unique(flat_list)\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = []\n",
    "for x in flat_list:\n",
    "    temp = []\n",
    "    temp.append(x)\n",
    "    temp.append(\"High Risk\")\n",
    "    big.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SHOP_XX3', 'High Risk'], ['SHOP_XX4', 'High Risk']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the result of association rules, we identified that SHOP_XX3 and SHOP_XX4 must be closed, which are / can be the warm bed of COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. An automate email will be sent to the business contact person\n",
    "1. for the business my_sejahtera id can be red flagged just like the supervised learning\n",
    "2. So if any scan on the id, it will be triggered a notice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
